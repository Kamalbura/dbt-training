================================================================================
DEDUPLICATION STRATEGIES
================================================================================
Author: dbt Training Course
Dataset: Shopify Orders
================================================================================

There are multiple ways to remove duplicates. Let's explore each:


================================================================================
STRATEGY 1: DISTINCT
================================================================================

The simplest approach - just use SELECT DISTINCT:

    SELECT DISTINCT *
    FROM orders

PROS:
    ✓ Simple to write
    ✓ Removes exact duplicate rows

CONS:
    ✗ Requires ALL columns to be identical
    ✗ Won't work if any column differs (like batch_runtime)
    ✗ No control over WHICH row to keep

EXAMPLE - WHY DISTINCT FAILS FOR YOUR DATA:

    ┌──────────┬─────────┬────────────────────┐
    │ order_id │ status  │ _daton_batch_runtime│
    ├──────────┼─────────┼────────────────────┤
    │ 12345    │ pending │ 1704067200000      │
    │ 12345    │ paid    │ 1705276800000      │  ← Status changed!
    └──────────┴─────────┴────────────────────┘

    SELECT DISTINCT * still returns 2 rows because they're different!
    
    We want the LATEST one (status = 'paid')


================================================================================
STRATEGY 2: GROUP BY + AGGREGATE
================================================================================

Group by the primary key and aggregate other columns:

    SELECT 
        order_id,
        MAX(status) AS status,           -- Takes alphabetically last
        MAX(_daton_batch_runtime) AS latest_sync
    FROM orders
    GROUP BY order_id

PROS:
    ✓ Guarantees one row per order_id
    ✓ Can choose which value to keep (MAX, MIN, etc.)

CONS:
    ✗ Need to explicitly handle EVERY column
    ✗ MAX() doesn't mean "from the latest row"
    ✗ Complex with many columns
    ✗ Can mix values from different rows!

EXAMPLE - WHY GROUP BY CAN MIX DATA:

    ┌──────────┬─────────┬─────────────┬────────────────────┐
    │ order_id │ status  │ total_price │ _daton_batch_runtime│
    ├──────────┼─────────┼─────────────┼────────────────────┤
    │ 12345    │ pending │ 100.00      │ 1704067200000      │  ← Sync 1
    │ 12345    │ paid    │ 95.00       │ 1705276800000      │  ← Sync 2 (refund)
    └──────────┴─────────┴─────────────┴────────────────────┘

    SELECT 
        order_id,
        MAX(status) AS status,           -- 'pending' > 'paid' alphabetically!
        MAX(total_price) AS total_price  -- 100.00 (wrong! actual is 95.00)
    FROM orders
    GROUP BY order_id
    
    Result:
    ┌──────────┬─────────┬─────────────┐
    │ order_id │ status  │ total_price │
    ├──────────┼─────────┼─────────────┤
    │ 12345    │ pending │ 100.00      │  ← WRONG! Mixed old status + old price
    └──────────┴─────────┴─────────────┘


================================================================================
STRATEGY 3: SUBQUERY WITH MAX (First Value Approach)
================================================================================

Join back to get the row with the maximum timestamp:

    SELECT o.*
    FROM orders o
    INNER JOIN (
        SELECT order_id, MAX(_daton_batch_runtime) AS max_runtime
        FROM orders
        GROUP BY order_id
    ) latest ON o.order_id = latest.order_id 
            AND o._daton_batch_runtime = latest.max_runtime

PROS:
    ✓ Gets entire row, no mixing
    ✓ Clear logic

CONS:
    ✗ STILL CAN HAVE DUPLICATES if two rows have same max timestamp!
    ✗ Requires a self-join (can be slow on large tables)
    ✗ More complex query

EXAMPLE - WHY SUBQUERY CAN STILL FAIL:

    ┌──────────┬─────────┬────────────────────┐
    │ order_id │ status  │ _daton_batch_runtime│
    ├──────────┼─────────┼────────────────────┤
    │ 12345    │ pending │ 1705276800000      │
    │ 12345    │ paid    │ 1705276800000      │  ← Same timestamp!
    └──────────┴─────────┴────────────────────┘

    The join returns BOTH rows because they have the same max timestamp!


================================================================================
STRATEGY 4: ROW_NUMBER() WINDOW FUNCTION  ⭐ RECOMMENDED
================================================================================

Use ROW_NUMBER() to assign a sequence, then filter to keep just row #1:

    WITH ranked AS (
        SELECT 
            *,
            ROW_NUMBER() OVER (
                PARTITION BY order_id              -- Group by primary key
                ORDER BY _daton_batch_runtime DESC -- Latest first
            ) AS row_num
        FROM orders
    )
    SELECT *
    FROM ranked
    WHERE row_num = 1

PROS:
    ✓ ALWAYS returns exactly one row per primary key
    ✓ Keeps entire row intact (no mixing)
    ✓ Deterministic - same input = same output
    ✓ Handles ties (first row in order wins)
    ✓ Easy to add tiebreakers
    ✓ Works with composite keys

CONS:
    ✗ Slightly more complex syntax
    ✗ Need to understand window functions

THIS IS WHAT WE USE IN YOUR dbt MODELS!


================================================================================
STRATEGY 5: QUALIFY CLAUSE (BigQuery Specific)
================================================================================

BigQuery has a special QUALIFY clause that simplifies ROW_NUMBER():

    SELECT *
    FROM orders
    QUALIFY ROW_NUMBER() OVER (
        PARTITION BY order_id 
        ORDER BY _daton_batch_runtime DESC
    ) = 1

PROS:
    ✓ Most concise syntax
    ✓ Same result as ROW_NUMBER() approach
    ✓ No subquery needed

CONS:
    ✗ BigQuery-specific (not portable to other databases)
    ✗ dbt models should work across databases when possible


================================================================================
COMPARISON SUMMARY
================================================================================

    ┌─────────────────────────┬───────────┬───────────┬──────────────┐
    │ Strategy                │ Reliable? │ Portable? │ Performance  │
    ├─────────────────────────┼───────────┼───────────┼──────────────┤
    │ DISTINCT                │ ✗ No      │ ✓ Yes     │ Fast         │
    │ GROUP BY + Aggregate    │ ✗ No      │ ✓ Yes     │ Fast         │
    │ Subquery with MAX       │ ✗ Risky   │ ✓ Yes     │ Slower       │
    │ ROW_NUMBER() ⭐         │ ✓ Yes     │ ✓ Yes     │ Good         │
    │ QUALIFY (BigQuery)      │ ✓ Yes     │ ✗ No      │ Good         │
    └─────────────────────────┴───────────┴───────────┴──────────────┘


================================================================================
WHY WE CHOSE ROW_NUMBER() FOR YOUR PROJECT
================================================================================

1. RELIABILITY
   - Guaranteed to return exactly 1 row per primary key
   - Handles edge cases (ties, nulls)

2. PORTABILITY
   - Works in BigQuery, Snowflake, Redshift, PostgreSQL, etc.
   - dbt models can be migrated to other warehouses

3. CLARITY
   - Explicit about what we're doing
   - Easy to read and understand
   - Self-documenting code

4. FLEXIBILITY
   - Easy to change sort order
   - Can add tiebreaker columns
   - Works with composite keys


NEXT FILE: 04_row_number_technique.txt
--------------------------------------
Deep dive into ROW_NUMBER() and how it works step by step.

